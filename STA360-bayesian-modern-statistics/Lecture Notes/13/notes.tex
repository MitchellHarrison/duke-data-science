\documentclass[titlepage, 12pt, leqno]{article}

% -------------------------------------------------- %
% -------------------- PACKAGES -------------------- %
% -------------------------------------------------- %
\usepackage{import}
\usepackage{pdfpages}
\usepackage{mathtools}
\usepackage{transparent}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{tcolorbox}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{parskip}
\usepackage{bbm}
\usepackage[margin = 1in]{geometry}
\tcbuselibrary{breakable}
\tcbset{breakable = true}


% -------------------------------------------------- %
% -------------- CUSTOM ENVIRONMENTS --------------- %
% -------------------------------------------------- %
\newtcolorbox{note}{colback=black!5!white,
                          colframe=black!55!white,
                          fonttitle=\bfseries,title=Note}

\newtcolorbox{ex}{colback=blue!5!white,
                          colframe=blue!55!white,
                          fonttitle=\bfseries,title=Example}

\newtcolorbox{definition}{colback=red!5!white,
                          colframe=red!55!white,
                          fonttitle=\bfseries,title=Definition}


% -------------------------------------------------- %
% ------------------- COMMANDS --------------------- %
% -------------------------------------------------- %
% Brackets, braces, etc. 
\newcommand{\abs}[1]{\lvert #1 \rvert}
\newcommand{\bigabs}[1]{\Bigl \lvert #1 \Bigr \rvert}
\newcommand{\bigbracket}[1]{\Bigl [ #1 \Bigr ]}
\newcommand{\bigparen}[1]{\Bigl ( #1 \Bigr )}
\newcommand{\ceil}[1]{\lceil #1 \rceil}
\newcommand{\floor}[1]{\lfloor #1 \rfloor}
\newcommand{\norm}[1]{\| #1 \|}
\newcommand{\bignorm}[1]{\Bigl \| #1 \Bigr \| #1}
\newcommand{\inner}[1]{\langle #1 \rangle}
\newcommand{\set}[1]{{ #1 }}


% -------------------------------------------------- %
% -------------------- SETUP ----------------------- %
% -------------------------------------------------- %
\title{\Huge{Lecture 13 - MCMC Diagnostics}}
\author{\large{Mitch Harrison}}
\date{\today}   
\begin{document}
\setlength{\parskip}{1\baselineskip}
\setlength{\parindent}{15pt}
\maketitle
\tableofcontents
\newpage


% -------------------------------------------------- %
% --------------------- BODY ----------------------- %
% -------------------------------------------------- %
\section{The Bayesian Statistical Procedure}

The following is the general structure of Bayesian statistical methods.
\begin{enumerate}
    \item We are trying to make some inferences using some data.
    \item We setup a data generative model (likelihood) $p(y|\vec\theta)$ and a
        prior on the model parameters $p(\theta)$ where $\vec \theta = 
        \{\theta_{1}, \cdots ,\theta_{n}\}$.
    \item Next, we wish to make inferences using the data we collect $\vec y =
        \{y_{1}, \cdots , y_{n}\}$. All inferences require the posterior
        $p(\vec \theta|\vec y)$, which we obtain via Bayes' rule.
    \item In general, the inferences we wish to make, e.g. $p(g(\vec \theta)
        \in A)$, are complicated or impossible to compute analytically. Here,
        \textbf{Monte Carlo} approximation helps. The key idea is that we use
        \textit{independent samples from the posterior} as an empirical 
        approximation to make inference.
    \item For non-conjugate models, obtaining samples from the posterior can be
        hard. We saw last time that \textbf{Gibbs sampling} lets us generate a
        series of \textit{dependent samples from the posterior} as an empirical
        approximation to make inference. The key idea is that if we sample a
        \textit{large number of samples $S$}, we should have some number
        $S_{ \text{eff}}<S$ effectively indipendent samples.
    \item Gibbs sampling is one of many methods (but not the only method) to
        \textbf{construct a Markov chain comprised of dependent samples from
        the target distribution}.
    \item Constructing a Markov chain of dependent samples and using these
        samples to approximate the target distribution is called \textbf{Markov
        chain Monte Carlo} (MCMC).
\end{enumerate}
Importantly, MCMC sampling algorithms \textit{are not models}. They do not
generate more information than is in $\vec y$ and $p(\vec \theta)$. They are
simply ways of "looking at" $p(\vec \theta|\vec y)$.

\begin{definition}
    A \textbf{target distribution} is a distribution in which we are interested
    in sampling. In Bayesian statistics, this is typically the 
    \textit{posterior distribution}.
\end{definition}

\pagebreak
\section{Properties of Markov Chain Monte Carlo}
\subsection{Toy example}
In this example, we have a target distribution (the joint probability
distribution of two variables $\theta$ and $\delta$). Let
\begin{align*}
    p(\delta = d) &=
    \begin{cases}
        .45 & d=1 \\
        .10 & d=2 \\
        .45 & d=4
    \end{cases}
    \\
    \{\theta|\delta = d\} & \sim 
    \begin{cases}
        N(-3, 1/3) & d=1 \\
        N(0, 1/3) & d=2 \\
        N(3, 1/3) & d=3
    \end{cases}
\end{align*}

\textbf{Exercise:} Construct a Gibbs sampler of the joint density.

\begin{note}
    This is a toy example. We can sample from the target distribution
    \textit{directly} as seen in the code example on the course website. 
    However, we will construct a Gibbs sampler for pedagogical purposes that 
    will become apparent momentarily.
\end{note}

To construct a Gibbs sampler, we need the full conditional distributions. We
are given $p(\theta|\delta)$, and we know from Bayes' rule that
\[
p(\delta|\theta) = \frac{p(\theta|\delta=d)p(\delta=d)}
{\sum_{d=1}^{3}p(\theta|\delta=d)p(\delta=d)}
\]
for $d \in  \{1,2,3\}$. The code to plot 1,000 Gibbs samples is as follows.
\pagebreak
\subsection{Code}
\begin{verbatim}
## fixed values ## 
mu = c(-3, 0, 3) # conditional means
s2 = rep(1 / 3, 3) # conditional sds
d = c(1, 2, 3) # sample space of delta
N = 1000 # chain length
w = c(.45, .1, .45) # delta probabilities

## Gibbs sampler ##
set.seed(360)
N = 1000 # number of Gibbs samples

theta = 0 # initial theta value
thd.mcmc = NULL
for(i in 1:N) {
d = sample(1:3 , 1, prob = w * dnorm(theta, mu, sqrt(s2))) 
theta = rnorm(1, mu[d], sqrt(s2[d]))
thd.mcmc = rbind(thd.mcmc, c(theta,d))
}
# note we take advantage that sample() in R does not require the probability
# to add up to 1

df = data.frame(theta = thd.mcmc[,1],
                delta = thd.mcmc[,2])

df %>%
  ggplot(aes(x = seq(1, nrow(df)), y = theta)) +
  geom_line() +
  theme_bw() +
  labs(y = TeX("\\theta"),
       x = "iteration",
       title = "Traceplot of 1000 Gibbs samples")
\end{verbatim}

The final visualization that this produces can be rendered in R or seen on the
course website. This visualization is effectively the path of a "particle"
moving through parameter space $\Theta$.

\pagebreak
\section{MCMC Terms}
\begin{definition}
    \textbf{Autocorrelation} describes how correlated consecutive values in the
    chain are. Mathematically, we compute the sample autocorrelation between
    elements in the sequence that are $t$ steps apart using
    \[
    acf_{t}(\phi) = \frac{\frac{1}{S-t}\sum_{s=1}^{S-t}(\phi_{s}-\bar \phi)
    (\phi_{s+t}-\bar \phi)}{\frac{1}{S-1}\sum_{s=1}^{S}(\phi_{s}-\bar \phi)^{2}}
    \]
    where $\phi$ is a sequence of length $S$ and $\bar \phi$ is the mean of the
    sequence. In practice, we use the \texttt{acf()}  function in R. For 
    example,

    \begin{verbatim}
    acf(thd.mcmc[,1], plot = FALSE)
    \end{verbatim}
\end{definition}

The higher the autocorrelation, the more samples we need to obtain a given
level of precision for our approximation. One way to state how precise our 
approximation is, is with \textit{effective sample size}.

\begin{definition}
    \textbf{Effective sample size}, intuitively, is the effective number of
    exact samples "contained" in the Markov chain (see Betancourt, 2018 linked
    on the course website). In practice, we use the 
    \texttt{coda::effectiveSize()} function in R to compute. For example,

    \begin{verbatim}
    library(coda)
    effectiveSize(thd.mcmc[,1])[[1]
    \end{verbatim}
\end{definition}

More precisely, the effective sample size (ESS) is the value $S_{ \text{eff}}$
such that
\[
    Var_{MCMC}[\bar \phi] = \frac{Var[\phi]}{S_{ \text{eff}}}
\]
In words, it is the number of independent Monte Carlo samples necessary to give
the same precision as the MCMC samples. For comparison, recall that
$Var_{MC}[\bar \phi] = Var[\phi]/S$.

\begin{definition}
    \textbf{Stationary} is when samples taken in one part of the chain have a
    similar distribution to samples taken from other parts of the chain.
    Intuitively, we want the particle to move from our arbitrary starting point
    to regions of higher probability*, then we will say that it has 
    \textit{achieved stability}.
    \begin{note}
        * Recall that probability is really a volume in high dimensions of
        parameter space, and so it is not enough for a pdf to evaluate to a
        high value. There must also be sufficient volume.
    \end{note}
\end{definition}

Traceplots are a great way to visually inspect whether a chain has
\textbf{converged}, or achieved \textit{stationarity}. In the traceplot given
on the course website, we see that samples from the beginning of the chain look
very different than the samples at the end.

\begin{definition}
    \textbf{Mixing} describes how well the particle moves between sets of
    high probability. Some might refer to this as how well the particle
    \textit{sojourns} across the "typical set" (regions of high probability).
\end{definition}

\end{document}
