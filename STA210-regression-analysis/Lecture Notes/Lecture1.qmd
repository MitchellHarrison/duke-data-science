---
title: "Lecture 1"
author: "Mitch Harrison"
format: pdf
editor: source
execute: 
  message: false
  warning: false
---
## Considerations for model constructions
- Prediction vs. Explanation
- Association vs. Causation
- Data-Driven vs. Theory-Driven
- Prospective vs. Retrospective

## Why linear models?
- they are foundational to more "sophisticated" techniques
- they are transparent to the modeler and the audience
- they are translational (like Optical Character Recognition [OCR])
- they are useful

## Linear Modeling Basics
The primary question of a model is "how does $X$ change $Y$?". Variablity is natural for these questions due to natural randomness. In this case, the relationship is __bivariate__.

## Means and variances
__Expectations__ are averages:
$$
E(Y) = \sum_y \times p_Y(y)
$$

__Variances__ are "expected squared deviations around the mean":
$$
Var(Y) = E\big[(Y - E(Y))^2\big]
$$

__Conditional__ means and variances (Y given X):
$$
E(Y|X = x) = \text{... some function of x}
$$
$$
Var(Y|X = x) = \text{... some other function of x}
$$
Possible formulas:
$$ 
E(Y|X = x) = \beta_0 + \beta_1x
$$
$$
Var(Y|X = x) = \sigma^2
$$
